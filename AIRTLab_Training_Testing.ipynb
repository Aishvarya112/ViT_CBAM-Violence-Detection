{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGknGDCLdYfp3s2OrihsPD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PlWsX4UAAUQy"},"outputs":[],"source":["class CreatePatches(nn.Module):\n","  def __init__(self, channels, patch_size, embed_dim):\n","    super().__init__()\n","    self.patch = nn.Conv2d(\n","            in_channels=channels,\n","            out_channels=embed_dim,\n","            kernel_size=patch_size,\n","            stride=patch_size\n","        )\n","  def forward(self, x):\n","        patches = self.patch(x).transpose(1, 2)\n","        patches = patches.transpose(2, 3)\n","        return patches"]},{"cell_type":"code","source":["class LayerNormalization(nn.Module):\n","    def __init__(self, embed_dim, epsilon=1e-5):\n","        super().__init__()\n","\n","        self.epsilon = epsilon\n","        self.pre_norm = nn.LayerNorm(embed_dim, eps=epsilon)\n","\n","    def forward(self, image):\n","        # Reshape the image to apply LayerNorm\n","        b, c, h, w = image.shape\n","        #print(image.shape)\n","        image_reshaped = image.reshape(b,-1,768)\n","        #print(image_reshaped.shape)\n","\n","        x_norm = self.pre_norm(image_reshaped)\n","\n","        # Reshape the normalized image back to its original shape\n","        x_norm = x_norm.reshape(b, h, w,c)\n","        x_norm = x_norm.transpose(2,3)\n","        #print(x_norm.shape)\n","\n","        return x_norm"],"metadata":{"id":"CkOgArveuTHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNlQHpHs6Yqf"},"outputs":[],"source":["class ChannelAttention(nn.Module):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n","        self.fc = nn.Sequential(\n","            nn.Linear(in_planes, in_planes // ratio),\n","            nn.ReLU(),\n","            nn.Linear(in_planes // ratio, in_planes)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = self.fc(self.avg_pool(x).view(x.size(0), -1))\n","        max_out = self.fc(self.max_pool(x).view(x.size(0), -1))\n","        out = avg_out + max_out\n","        return self.sigmoid(out).view(x.size(0), -1, 1, 1)\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size//2)\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        out = torch.cat([avg_out, max_out], dim=1)\n","        out = self.conv(out)\n","        return torch.sigmoid(out)\n","\n","class CBAM(nn.Module):\n","    def __init__(self, in_planes):\n","        super(CBAM, self).__init__()\n","        self.ca = ChannelAttention(in_planes)\n","        self.sa = SpatialAttention()\n","\n","    def forward(self, x):\n","        out = x * self.ca(x)\n","        out = out * self.sa(out)\n","        #print(out.shape)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiqtpIFrAzpZ"},"outputs":[],"source":["class Transformers1(nn.Module):\n","      def __init__(self, embed_dim, hidden_dims, epsilon, ratio, kernel_size = 2, dropout=0.0):\n","        super().__init__()\n","\n","        self.pre_norm = (LayerNormalization(embed_dim, epsilon=1e-6))\n","        self.attention = (CBAM(embed_dim))\n","        self.norm = nn.LayerNorm(embed_dim, epsilon)\n","        self.MLP = nn.Sequential(\n","            nn.Linear(embed_dim, hidden_dims),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dims, embed_dim),\n","            nn.Dropout(dropout)\n","        )\n","      def forward(self, x):\n","        b,h,w,c = x.shape\n","        #print(x.shape)\n","        x_norm = self.pre_norm(x)\n","        x_norm = rearrange(x, 'b h w c -> b c h w')\n","        #print(x_norm.shape)\n","        x_att = self.attention(x_norm)\n","        #print(x_att.shape)\n","        x_re = x_att.transpose(1,2)\n","        x_re = x_re.transpose(2,3)\n","        x = x + x_re\n","\n","        x_red = x.reshape(-1,768)\n","\n","        x_red = x_red + self.MLP(self.norm(x_red))\n","        x_red = x_red.view(*x.size())\n","        #print(x_red.shape)\n","        return x_red"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TmCEiGMECcM"},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)\n","    def forward(self, x):\n","        h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7a_5PhQt8t5"},"outputs":[],"source":["class ViTLSTM(nn.Module):\n","    def __init__(\n","        self, d_model, max_len,epsilon = 1e-05,\n","        img_size=192,\n","        in_channels=3,\n","        patch_size=16,\n","        embed_dim=768,\n","        hidden_dims=3072,\n","        num_layers=12,\n","        dropout=0.1,\n","        num_classes=2,\n","        ratio = 16,\n","        kernel_size = 7, hidden_size = 1024, input_size = 768, n_layers = 2\n","    ):\n","        super().__init__()\n","        self.patch_size = patch_size\n","        num_patches = (img_size//patch_size) ** 2\n","        self.patches = CreatePatches(\n","            channels=in_channels,\n","            embed_dim=embed_dim,\n","            patch_size=patch_size\n","        )\n","\n","        self.position_embedding = PositionalEncoding(max_len,d_model)\n","        self.attn_layers = nn.ModuleList([])\n","        for _ in range(num_layers):\n","            self.attn_layers.append(\n","                Transformers1(embed_dim, hidden_dims,  ratio, kernel_size, dropout, epsilon)\n","            )\n","        self.dropout = nn.Dropout(dropout)\n","        self.ln = nn.LayerNorm(embed_dim, eps=1e-06)\n","        self.lstm1 = LSTMModel(input_size, hidden_size, n_layers)\n","\n","\n","        self.flat = nn.Flatten(1)\n","        self.fc1 = nn.Linear(147456, 512)\n","        self.relu1 = nn.LeakyReLU(0.1)\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.fc2 = nn.Linear(512, 128)\n","        self.relu2 = nn.LeakyReLU(0.1)\n","        self.drop = nn.Dropout(0.5)\n","        self.fc3 = nn.Linear(128, 16)\n","        self.relu3 = nn.LeakyReLU(0.1)\n","        self.fc5 = nn.Linear(16, 2)\n","        self.relu5 = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.patches(x)\n","        #print(\"Create_Patch: \", x.shape)\n","        b,h,w,c = x.shape\n","        self.max_len = h*w\n","        x = x.reshape(b, -1, 768)\n","        x = self.position_embedding(x)\n","        x = self.dropout(x)\n","        x = x.reshape(b,h,w,c)\n","        for layer in self.attn_layers:\n","            x = layer(x)\n","        x = self.ln(x)\n","        x = x.reshape(b, -1, 768)\n","\n","        x_l = self.lstm1(x)\n","        #print(x.shape)\n","        x = self.flat(x_l)\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.bn1(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.drop(x)\n","        x = self.fc3(x)\n","        x = self.relu3(x)\n","        x = self.fc5(x)\n","        x = self.relu5(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1195,"status":"ok","timestamp":1716883128341,"user":{"displayName":"Aishvarya Garg","userId":"03678663851274929969"},"user_tz":-330},"id":"uEXEn0k5yOZ_","outputId":"35dd8337-bb11-4a1a-a715-c93e45aa3a63"},"outputs":[{"output_type":"stream","name":"stdout","text":["ViTLSTM(\n","  (patches): CreatePatches(\n","    (patch): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","  )\n","  (position_embedding): PositionalEncoding()\n","  (attn_layers): ModuleList(\n","    (0-11): 12 x Transformers1(\n","      (pre_norm): LayerNormalization(\n","        (pre_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (attention): CBAM(\n","        (ca): ChannelAttention(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (max_pool): AdaptiveMaxPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=768, out_features=48, bias=True)\n","            (1): ReLU()\n","            (2): Linear(in_features=48, out_features=768, bias=True)\n","          )\n","          (sigmoid): Sigmoid()\n","        )\n","        (sa): SpatialAttention(\n","          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","        )\n","      )\n","      (norm): LayerNorm((768,), eps=16, elementwise_affine=True)\n","      (MLP): Sequential(\n","        (0): Linear(in_features=768, out_features=3072, bias=True)\n","        (1): GELU(approximate='none')\n","        (2): Dropout(p=1e-05, inplace=False)\n","        (3): Linear(in_features=3072, out_features=768, bias=True)\n","        (4): Dropout(p=1e-05, inplace=False)\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (lstm1): LSTMModel(\n","    (lstm): LSTM(768, 1024, num_layers=2, batch_first=True)\n","  )\n","  (flat): Flatten(start_dim=1, end_dim=-1)\n","  (fc1): Linear(in_features=147456, out_features=512, bias=True)\n","  (relu1): LeakyReLU(negative_slope=0.1)\n","  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc2): Linear(in_features=512, out_features=128, bias=True)\n","  (relu2): LeakyReLU(negative_slope=0.1)\n","  (drop): Dropout(p=0.5, inplace=False)\n","  (fc3): Linear(in_features=128, out_features=16, bias=True)\n","  (relu3): LeakyReLU(negative_slope=0.1)\n","  (fc5): Linear(in_features=16, out_features=2, bias=True)\n","  (relu5): Sigmoid()\n",")\n"]}],"source":["import math\n","from torch.optim.rmsprop import RMSprop\n","from torch.optim import Adam, SGD,RMSprop\n","model = ViTLSTM( max_len = 144,d_model = 768,\n","                epsilon = 1e-05,\n","        in_channels = 3,\n","        img_size=192,\n","        patch_size=16,\n","        embed_dim=768,\n","        hidden_dims=3072,\n","        num_layers=12,\n","        dropout=0.1,\n","        num_classes=2,\n","        ratio = 16,\n","        kernel_size = 7, hidden_size = 1024, input_size = 768, n_layers = 2\n","    ).to(device)\n","print(model)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = SGD(model.parameters(),momentum = 0.9, lr = 0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zM4iyMyt6kwV"},"outputs":[],"source":["# Training loop\n","nb_epoch = 25\n","for epoch in range(nb_epoch):\n","    model.train()\n","    train_running_loss = 0.0\n","    val_running_loss = 0.0\n","    #val_running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for i, (images, labels) in enumerate(train_dl):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        #print(\"train: \",i)\n","\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_running_loss += loss.item()\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    train_accuracy = correct_train / total_train\n","    # Calculate average loss for the epoch\n","    train_average_loss = train_running_loss / len(train_dl)\n","    #print(\"Train done\")\n","\n","\n","    # Validation loop\n","    model.eval()\n","    correct_val = 0\n","    total_val = 0\n","\n","    with torch.no_grad():\n","        for i, (images, labels) in enumerate(val_dl):\n","\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","\n","            val_running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    # Calculate validation accuracy\n","    val_accuracy = correct_val / total_val\n","    # Calculate average loss for the epoch\n","    val_average_loss = val_running_loss / len(val_dl)\n","\n","    print(f\"Epoch {epoch+1} -- Train Loss: {train_average_loss:.2f} -- Train Accuracy: {train_accuracy:.2f} -- Validation Loss: {val_average_loss:.2f} -- Validation Accuracy: {val_accuracy:.2f} \")\n","\n","# Testing loop\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for i, (images, labels) in enumerate(test_dl):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","# Calculate test accuracy\n","accuracy = correct / total\n","\n","print(f\"Test Accuracy: {accuracy:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4VE7b_Zh4Gl","executionInfo":{"status":"ok","timestamp":1716901989798,"user_tz":-330,"elapsed":15527,"user":{"displayName":"Aishvarya Garg","userId":"03678663851274929969"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1b61f01-ccad-4ee0-c979-9278eac2d291"},"outputs":[{"output_type":"stream","name":"stdout","text":["Actual Value : tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n","        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n","        0, 0, 0], device='cuda:0')  Predicted Value : tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n","        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n","        0, 0, 0], device='cuda:0')\n","Actual Value : tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n","        1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n","        0, 0, 1], device='cuda:0')  Predicted Value : tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n","        1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n","        0, 0, 1], device='cuda:0')\n","Actual Value : tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n","        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n","        1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0], device='cuda:0')  Predicted Value : tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n","        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n","        1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0], device='cuda:0')\n","Actual Value : tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n","        1, 0, 0], device='cuda:0')  Predicted Value : tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n","        1, 0, 0], device='cuda:0')\n","Actual Value : tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n","        0, 0, 0], device='cuda:0')  Predicted Value : tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n","        0, 0, 0], device='cuda:0')\n","Actual Value : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n","        0, 1, 0], device='cuda:0')  Predicted Value : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n","        0, 1, 0], device='cuda:0')\n","Actual Value : tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n","        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n","        1, 1, 0], device='cuda:0')  Predicted Value : tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n","        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n","        1, 1, 0], device='cuda:0')\n","\n","\n","Accuracy of the network on the 525 test images: 99.80952380952381 %\n"]}],"source":["from sklearn.metrics import precision_score\n","with torch.no_grad():\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    for images, labels in test_dl:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).float().sum().item()\n","\n","        print(f\"Actual Value : {labels}  Predicted Value : {predicted}\")\n","\n","    print(\"\\n\")\n","    print(\"Accuracy of the network on the {} test images: {} %\".format(total, 100 * correct / total))\n","    # print(precision)"]},{"cell_type":"code","source":[],"metadata":{"id":"8j4aLEJD0z15"},"execution_count":null,"outputs":[]}]}